{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors and Models\n",
    "We've more or less settled on using TFIDF as the vectorizer of record. This is because we are looking at frequencies across a range of documents. We went to all the trouble of creating corpora of various lengths in order to have a better experimental field for the research.\n",
    "\n",
    "Edit of 4 Apr 2017: I'm still not sure that my method is the best method possible. I'd like to try doing the same thing with pipelines to perhaps expedite the process, or at least make it grid search ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twain = 1 \n",
    "Wilde = 2 \n",
    "Lincoln = 3\n",
    "///\n",
    "D_Twain = 10 \n",
    "D_Wilde = 20 \n",
    "D_Lincoln = 30\n",
    "///\n",
    "Modern = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000-, 500-, and 100-record samples for each original writer - Twain, Wilde, Lincoln, and Modern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_1k_H = pd.read_csv('_CSVs/df_1k_H.csv', index_col=0)\n",
    "df_1k_W = pd.read_csv('_CSVs/df_1k_W.csv', index_col=0)\n",
    "df_1k_S = pd.read_csv('_CSVs/df_1k_S.csv', index_col=0)\n",
    "\n",
    "df_500_H = pd.read_csv('_CSVs/df_500_H.csv', index_col=0)\n",
    "df_500_W = pd.read_csv('_CSVs/df_500_W.csv', index_col=0)\n",
    "df_500_S = pd.read_csv('_CSVs/df_500_S.csv', index_col=0)\n",
    "\n",
    "df_100_H = pd.read_csv('_CSVs/df_100_H.csv', index_col=0)\n",
    "df_100_W = pd.read_csv('_CSVs/df_100_W.csv', index_col=0)\n",
    "df_100_S = pd.read_csv('_CSVs/df_100_S.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Pipelines\n",
    "This is a bit odd. It seems to me that since we're ultimately using the TF-IDF transformer, we need multiple documents to compare frequencies of. So, to simulate 'multiple documents' when I had already combined everything into one document, I split the several authors into groups of different numbers of observations (1000, 500, and 100 rows) at different levels (cHaracter, Word, and Sentence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#wild_data = pd.read_csv('quotes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1k_H = df_1k_H['0'].values #1000 observations at the character level\n",
    "y_1k_H = df_1k_H['code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1k_W = df_1k_W['0'].values #1000 observations at the word level\n",
    "y_1k_W = df_1k_W['code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_1k_S = df_1k_S['0'].values #1000 observations at the sentence level\n",
    "y_1k_S = df_1k_S['code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    #'vect__decode_error': ('ignore'),\n",
    "    'vect__analyzer': ('word', 'char'),\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (3, 3), (4, 4)),  # individually checking uni- through tetragrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__fit_prior': (True, False),\n",
    "    #'clf__n_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, scoring='precision_macro', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed: 101.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        st...False,\n",
       "         use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'vect__analyzer': ('word', 'char'), 'vect__ngram_range': ((1, 1), (1, 2), (2, 2), (3, 3), (4, 4)), 'clf__alpha': (1e-05, 1e-06), 'clf__fit_prior': (True, False), 'vect__max_df': (0.5, 0.75, 1.0)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='precision_macro', verbose=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_1k_H, y_1k_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 1e-05,\n",
       " 'clf__fit_prior': True,\n",
       " 'vect__analyzer': 'char',\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__ngram_range': (3, 3)}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93701123599435088"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest regressor, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''For some reason, I didn't look at the starter code and spent the better part of th last week trying to come up,\n",
    "from scratch and without this guidance, the scraper code below. I gave up and went with Import.IO, which pulled\n",
    "everything for me.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "html = urllib.urlopen(URL).read()\n",
    "soup = BeautifulSoup(html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "\n",
    "- **Make sure these functions are robust and can handle cases where the data/field may not be available.**\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it\n",
    "    - Remember to use `try/except` if you anticipate errors\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and starting points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>snippet</th>\n",
       "      <th>location</th>\n",
       "      <th>title/_source</th>\n",
       "      <th>title</th>\n",
       "      <th>title/_title</th>\n",
       "      <th>title/_text</th>\n",
       "      <th>pageUrl</th>\n",
       "      <th>salary</th>\n",
       "      <th>company/_text</th>\n",
       "      <th>company/_source</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Experience working with imperfect data. At Civ...</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>/rc/clk?jk=cb86f3205f73582a&amp;fccid=85806092f576...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=cb86f3205f7358...</td>\n",
       "      <td>New Graduate - Data Scientist</td>\n",
       "      <td>New Graduate - Data Scientist</td>\n",
       "      <td>http://www.indeed.com/jobs?q=%22data+scientist...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chief Data Scientist – Oil &amp; Gas Analytics Gra...</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>/cmp/Digitek-Corp-Solution-Inc.-(DCSI)/jobs/Ch...</td>\n",
       "      <td>http://www.indeed.com/cmp/Digitek-Corp-Solutio...</td>\n",
       "      <td>Chief Data Scientist – Oil &amp; Gas Analytics</td>\n",
       "      <td>Chief Data Scientist – Oil &amp; Gas Analytics</td>\n",
       "      <td>http://www.indeed.com/jobs?q=%22data+scientist...</td>\n",
       "      <td>$170,000 a year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Data Scientist Analytics role has work acr...</td>\n",
       "      <td>Mountain View, CA</td>\n",
       "      <td>/rc/clk?jk=342373f6d9bee6ab&amp;fccid=1639254ea847...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=342373f6d9bee6...</td>\n",
       "      <td>Data Scientist, Analytics (WhatsApp)</td>\n",
       "      <td>Data Scientist, Analytics (WhatsApp)</td>\n",
       "      <td>http://www.indeed.com/jobs?q=%22data+scientist...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>/cmp/Facebook?from=SERP&amp;campaignid=serp-linkco...</td>\n",
       "      <td>http://www.indeed.com/cmp/Facebook?from=SERP&amp;c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US Citizenship is required in order to obtain ...</td>\n",
       "      <td>Reston, VA 20191</td>\n",
       "      <td>/rc/clk?jk=3b436f2ebaf33c60&amp;fccid=6ccb0eba9956...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=3b436f2ebaf33c...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/jobs?q=%22data+scientist...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engility Corporation</td>\n",
       "      <td>/cmp/Engility-Corp?from=SERP&amp;campaignid=serp-l...</td>\n",
       "      <td>http://www.indeed.com/cmp/Engility-Corp?from=S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a Data Scientist, you have the ability to l...</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>/rc/clk?jk=c2142d8baff9d10b&amp;fccid=34a475954feb...</td>\n",
       "      <td>http://www.indeed.com/rc/clk?jk=c2142d8baff9d1...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/jobs?q=%22data+scientist...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DoubleDutch</td>\n",
       "      <td>/cmp/Doubledutch?from=SERP&amp;campaignid=serp-lin...</td>\n",
       "      <td>http://www.indeed.com/cmp/Doubledutch?from=SER...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             snippet  \\\n",
       "0  Experience working with imperfect data. At Civ...   \n",
       "1  Chief Data Scientist – Oil & Gas Analytics Gra...   \n",
       "2  The Data Scientist Analytics role has work acr...   \n",
       "3  US Citizenship is required in order to obtain ...   \n",
       "4  As a Data Scientist, you have the ability to l...   \n",
       "\n",
       "                                         location  \\\n",
       "0                                     Chicago, IL   \n",
       "1                                    San Jose, CA   \n",
       "2                               Mountain View, CA   \n",
       "3                                Reston, VA 20191   \n",
       "4  San Francisco, CA 94103 (South Of Market area)   \n",
       "\n",
       "                                       title/_source  \\\n",
       "0  /rc/clk?jk=cb86f3205f73582a&fccid=85806092f576...   \n",
       "1  /cmp/Digitek-Corp-Solution-Inc.-(DCSI)/jobs/Ch...   \n",
       "2  /rc/clk?jk=342373f6d9bee6ab&fccid=1639254ea847...   \n",
       "3  /rc/clk?jk=3b436f2ebaf33c60&fccid=6ccb0eba9956...   \n",
       "4  /rc/clk?jk=c2142d8baff9d10b&fccid=34a475954feb...   \n",
       "\n",
       "                                               title  \\\n",
       "0  http://www.indeed.com/rc/clk?jk=cb86f3205f7358...   \n",
       "1  http://www.indeed.com/cmp/Digitek-Corp-Solutio...   \n",
       "2  http://www.indeed.com/rc/clk?jk=342373f6d9bee6...   \n",
       "3  http://www.indeed.com/rc/clk?jk=3b436f2ebaf33c...   \n",
       "4  http://www.indeed.com/rc/clk?jk=c2142d8baff9d1...   \n",
       "\n",
       "                                 title/_title  \\\n",
       "0               New Graduate - Data Scientist   \n",
       "1  Chief Data Scientist – Oil & Gas Analytics   \n",
       "2        Data Scientist, Analytics (WhatsApp)   \n",
       "3                              Data Scientist   \n",
       "4                              Data Scientist   \n",
       "\n",
       "                                  title/_text  \\\n",
       "0               New Graduate - Data Scientist   \n",
       "1  Chief Data Scientist – Oil & Gas Analytics   \n",
       "2        Data Scientist, Analytics (WhatsApp)   \n",
       "3                              Data Scientist   \n",
       "4                              Data Scientist   \n",
       "\n",
       "                                             pageUrl           salary  \\\n",
       "0  http://www.indeed.com/jobs?q=%22data+scientist...              NaN   \n",
       "1  http://www.indeed.com/jobs?q=%22data+scientist...  $170,000 a year   \n",
       "2  http://www.indeed.com/jobs?q=%22data+scientist...              NaN   \n",
       "3  http://www.indeed.com/jobs?q=%22data+scientist...              NaN   \n",
       "4  http://www.indeed.com/jobs?q=%22data+scientist...              NaN   \n",
       "\n",
       "          company/_text                                    company/_source  \\\n",
       "0                   NaN                                                NaN   \n",
       "1                   NaN                                                NaN   \n",
       "2              Facebook  /cmp/Facebook?from=SERP&campaignid=serp-linkco...   \n",
       "3  Engility Corporation  /cmp/Engility-Corp?from=SERP&campaignid=serp-l...   \n",
       "4           DoubleDutch  /cmp/Doubledutch?from=SERP&campaignid=serp-lin...   \n",
       "\n",
       "                                             company  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2  http://www.indeed.com/cmp/Facebook?from=SERP&c...  \n",
       "3  http://www.indeed.com/cmp/Engility-Corp?from=S...  \n",
       "4  http://www.indeed.com/cmp/Doubledutch?from=SER...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/charlesrice/desktop/Jobhuntr 7-Sept-2016.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ew. What an uglybunch of data that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's clean it up a bit\n",
    "df.drop(['snippet', 'title/_source', 'title', 'title/_title', 'pageUrl', 'company/_source', 'company'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()\n",
    "# Much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location            0\n",
      "title/_text         0\n",
      "salary           2879\n",
      "company/_text    1351\n",
      "dtype: int64\n",
      "\n",
      "location         0.000000\n",
      "title/_text      0.000000\n",
      "salary           0.928710\n",
      "company/_text    0.435806\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Any nulls to speak of?\n",
    "print df.isnull().sum()\n",
    "print\n",
    "print df.isnull().sum()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Good grief that's a lot of nulls. Almost all of our data is lacking the data we want. Great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print df.duplicated().sum()/len(df)\n",
    "df[df.duplicated()]\n",
    "df.dropna(subset=['salary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Given the search terms used in the extractor, removing duplicate entries would remove about 50% of the dataset, which\n",
    "# is already small enough as it is. Since the feature set is so small, there's no way to know if something is a legit \n",
    "# duplicate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hour = 'an hour'\n",
    "# for elem in df.salary:\n",
    "#     if hour in elem:\n",
    "#         elem == 42 # dead end road for what I'm trying to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the hourly and monthly salaries\n",
    "df = df[df.salary.str.contains(' an hour') == False]\n",
    "\n",
    "df = df[df.salary.str.contains(' a month')== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There's still a lot of unnecssary strings around that lovely salary data.\n",
    "\n",
    "df['sal_1'] = df.salary.str.rstrip('a year')\n",
    "\n",
    "df['sal_2'] = df.sal_1.str.replace('$','')\n",
    "\n",
    "df['sal_2'] = df.sal_2.str.replace(',', '')\n",
    "\n",
    "df['sal_2'] = df.sal_2.str.split(' - ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# d = [[1.1, 2.1], [4.4, 3.3]]\n",
    "\n",
    "# def interize(list):\n",
    "#     for x in d:\n",
    "#         for y in x:\n",
    "#             y = int(y)\n",
    "#     return y\n",
    "\n",
    "# # interize(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Need to make the salaries numbers and not strings.\n",
    "\n",
    "df['sal_2'] = df['sal_2'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for elem in df.sal_2:\n",
    "    for v in elem:\n",
    "        print type(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, get the salaries or the average salaries in the event of a range\n",
    "sal_3 = []\n",
    "for elem in df.sal_2:\n",
    "    if len(elem) == 2:\n",
    "        s = (elem[0] + elem[1])/2\n",
    "        sal_3.append(s)\n",
    "    else:\n",
    "        s = elem[0]\n",
    "        sal_3.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(sal_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The index was all mucked up from earlier slices, so it required a reset before we could move forward\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Append the new average salary information to the existing dataframe. Although in retrospect, I probably could have\n",
    "# mapped some function onto the salary column\n",
    "\n",
    "df2 = pd.DataFrame(data=sal_3, columns=['avg_sal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.drop(['salary', 'sal_1', 'sal_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pnames = ['location', 'title', 'company', 'avg_sal']\n",
    "df3.columns = pnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# That's cleaned up, but it's still messy. We've got unrecognized overlap due to discrepancies in names.\n",
    "df3.location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's clean them up the most efficient way we know how: regex\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['location'] = df3['location'].str.replace(r\"\\(.*\\)\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3['location'] = df3['location'].str.replace(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3['location'] = df3['location'].str.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "# Turn all that into a function. Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "df3.to_csv('clean_job.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_job.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choice the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>avg_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Jose CA</td>\n",
       "      <td>Chief Data Scientist – Oil &amp; Gas Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arlington VA</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>St. Louis MO</td>\n",
       "      <td>SENIOR DATA SCIENTIST</td>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York NY</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Norwalk CT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       location                                       title  \\\n",
       "0   San Jose CA  Chief Data Scientist – Oil & Gas Analytics   \n",
       "1  Arlington VA                              Data Scientist   \n",
       "2  St. Louis MO                       SENIOR DATA SCIENTIST   \n",
       "3   New York NY                              Data Scientist   \n",
       "4    Norwalk CT                              Data Scientist   \n",
       "\n",
       "                 company  avg_sal  \n",
       "0                    NaN   170000  \n",
       "1     Jobspring Partners    75000  \n",
       "2    Analytic Recruiting    90000  \n",
       "3  Workbridge Associates   140000  \n",
       "4                    NaN   112500  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at our lovely, clean dataframe before we muck it all up again\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med = df['avg_sal'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126356.0052631579"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med # mean salary for the dataset is 126,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check salaries against the median\n",
    "high = []\n",
    "for row in df.avg_sal:\n",
    "    high.append(row > med)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=high, columns=['high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.join(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['high'] = df.high.map({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Encode the location names with numbers. Binary would probably be better, All those dummies are hard to interpret\n",
    "df['locus'] = loc_enc.fit_transform(df.location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_enc.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.563158\n",
       "0    0.436842\n",
       "Name: high, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.high.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random chance would suggest a 56% chance of correctly predicting a salary above the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold, KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "X = df.locus.values\n",
    "y = df.high.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X\n",
    "X = X[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20,  7],\n",
       "       [ 5, 25]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      0.74      0.77        27\n",
      "          1       0.78      0.83      0.81        30\n",
      "\n",
      "avg / total       0.79      0.79      0.79        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5625  ,  0.796875,  1.      ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf, X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pat1 = 'senior'\n",
    "pat2 = 'sr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "df['title_in1'] = df.title.str.contains(pat1, case=False)\n",
    "df['title_in2'] = df.title.str.contains(pat2, case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title_in1'] = df.title_in1.map({False:0, True:1})\n",
    "df['title_in2'] = df.title_in2.map({False:0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    147\n",
       "1     43\n",
       "Name: title_in1, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title_in1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    167\n",
       "1     23\n",
       "Name: title_in2, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title_in2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['title_in'] = df.title_in1 + df.title_in2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    124\n",
       "1     66\n",
       "Name: title_in, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title_in.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Scientist                                                     58\n",
       "Lead Data Scientist                                                24\n",
       "Sr. Data Scientist                                                 23\n",
       "Senior Data Scientist - Security Experience is Huge                21\n",
       "Senior Data Scientist                                               6\n",
       "Data Scientist - Experienced                                        2\n",
       "Principal Statistical Analyst / Data Scientist ( USC or GC O...     1\n",
       "Senior Data Scientist for Multi-Billion Dollar Hedge Fund           1\n",
       "Senior Marketing Data Scientist                                     1\n",
       "Principal Data Scientist - Supply Chain                             1\n",
       "Director of Data Science/Chief Product Officer                      1\n",
       "California Client seeks Ph.D. or M.S. Property and Casualty...      1\n",
       "Data Scientist/Analytics Manager with SQL (requires Secret C...     1\n",
       "Predictive Analytics Professionals-- ROAD WARRIORS                  1\n",
       "Data Engineer (ElasticSearch/Kafka) -global eCommerce - Bang...     1\n",
       "Senior Data Scientist - Insurance                                   1\n",
       "Senior/Lead Data Scientist                                          1\n",
       "Lead Data Scientist for Global Digital Media Company                1\n",
       "Acquisition Marketing Data Scientist                                1\n",
       "MySQL Database Administrator                                        1\n",
       "Principal Data Scientist - Consultancy - Boston                     1\n",
       "Community Assessment Specialist                                     1\n",
       "Executive Director                                                  1\n",
       "Data Scientist 5796057                                              1\n",
       "SENIOR DATA SCIENTIST                                               1\n",
       "Data Scientist (Data Engineer)                                      1\n",
       "Senior Data Scientist for Top Global Retail Company                 1\n",
       "Senior Business Intelligence Analyst/ Data Scientist                1\n",
       "Senior Research Analyst/Data Scientist                              1\n",
       "Lead Data Scientist -- IoT/Biotech                                  1\n",
       "                                                                   ..\n",
       "Senior Analyst¸ Data Science                                        1\n",
       "Data Scientist (Software Engineering)                               1\n",
       "Data Scientist-Senior/Ph.D                                          1\n",
       "Digital Data Scientist, PM                                          1\n",
       "C++/Python Algo Developer/Data Scientist                            1\n",
       "Chief Data Scientist – Oil & Gas Analytics                          1\n",
       "Data Scientist/Analyst                                              1\n",
       "Junior Data Scientist - R, Web Scraping, Database Algorithms        1\n",
       "Asst. Director¸ Data Science                                        1\n",
       "Computer Systems Architect                                          1\n",
       "Senior Statistician / Senior Data Scientist                         1\n",
       "Data Scientist ($90k - $100k)                                       1\n",
       "Data Scientist at Video Software Company                            1\n",
       "Python Data Scientist                                               1\n",
       "Data Scientist (TS/SCI)                                             1\n",
       "Senior Data Scientist (Deep Learning or NLP)                        1\n",
       "Data Scientist-Supply Chain (Manhattan)                             1\n",
       "Lead Data Scientist (Graph Analytics)                               1\n",
       "Data Scientist - Text Analytics - SQL, R, SAS                       1\n",
       "Senior Data Scientist (Northern New Jersey)                         1\n",
       "Data Scientist (Machine Learning)                                   1\n",
       "Chief Data Scientist                                                1\n",
       "Senior Data Scientist, Machine Learning                             1\n",
       "Principal Data Scientist                                            1\n",
       "Predictive Analytics - Data Scientist                               1\n",
       "Director, Data Scientist, Marketing Science                         1\n",
       "Data Scientist (Natural Language Processing)                        1\n",
       "Senior Data Scientist / Machine Learning                            1\n",
       "Senior Data Scientist with Extensive Machine Learning Skills        1\n",
       "Director of Data Science and Predictive Modeling                    1\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_sal</th>\n",
       "      <th>high</th>\n",
       "      <th>locus</th>\n",
       "      <th>title_in1</th>\n",
       "      <th>title_in2</th>\n",
       "      <th>title_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_sal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869775</td>\n",
       "      <td>-0.042897</td>\n",
       "      <td>0.311877</td>\n",
       "      <td>0.238406</td>\n",
       "      <td>0.437416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.869775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>0.222758</td>\n",
       "      <td>0.294322</td>\n",
       "      <td>0.397402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locus</th>\n",
       "      <td>-0.042897</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080561</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.383890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_in1</th>\n",
       "      <td>0.311877</td>\n",
       "      <td>0.222758</td>\n",
       "      <td>0.080561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.200716</td>\n",
       "      <td>0.741335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_in2</th>\n",
       "      <td>0.238406</td>\n",
       "      <td>0.294322</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>-0.200716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_in</th>\n",
       "      <td>0.437416</td>\n",
       "      <td>0.397402</td>\n",
       "      <td>0.383890</td>\n",
       "      <td>0.741335</td>\n",
       "      <td>0.508680</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_sal      high     locus  title_in1  title_in2  title_in\n",
       "avg_sal    1.000000  0.869775 -0.042897   0.311877   0.238406  0.437416\n",
       "high       0.869775  1.000000 -0.154623   0.222758   0.294322  0.397402\n",
       "locus     -0.042897 -0.154623  1.000000   0.080561   0.457014  0.383890\n",
       "title_in1  0.311877  0.222758  0.080561   1.000000  -0.200716  0.741335\n",
       "title_in2  0.238406  0.294322  0.457014  -0.200716   1.000000  0.508680\n",
       "title_in   0.437416  0.397402  0.383890   0.741335   0.508680  1.000000"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['title_in1', 'title_in2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_sal</th>\n",
       "      <th>high</th>\n",
       "      <th>locus</th>\n",
       "      <th>title_in</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg_sal</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869775</td>\n",
       "      <td>-0.042897</td>\n",
       "      <td>0.437416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>0.869775</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>0.397402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>locus</th>\n",
       "      <td>-0.042897</td>\n",
       "      <td>-0.154623</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.383890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_in</th>\n",
       "      <td>0.437416</td>\n",
       "      <td>0.397402</td>\n",
       "      <td>0.383890</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           avg_sal      high     locus  title_in\n",
       "avg_sal   1.000000  0.869775 -0.042897  0.437416\n",
       "high      0.869775  1.000000 -0.154623  0.397402\n",
       "locus    -0.042897 -0.154623  1.000000  0.383890\n",
       "title_in  0.437416  0.397402  0.383890  1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_2 = df[['locus', 'title_in']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_2_train, X_2_test, y_2_train, y_2_test = train_test_split(X_2, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_2.fit(X_2_train, y_2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_2 = rf_2.predict(X_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 12],\n",
       "       [ 2, 28]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_2_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.56      0.68        27\n",
      "          1       0.70      0.93      0.80        30\n",
      "\n",
      "avg / total       0.79      0.75      0.74        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_2_test, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_2 = cross_val_score(rf_2, X_2, y, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.53846154,  0.43589744,  0.84210526,  1.        ,  1.        ])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "Let's try treating this as a regression problem. \n",
    "\n",
    "- Train a random forest regressor on the regression problem and predict your dependent.\n",
    "- Evaluate the score with a 5-fold cross-validation\n",
    "- Do a scatter plot of the predicted vs actual scores for each of the 5 folds, do they match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = logr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.685314685314685"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 26],\n",
       "       [ 6, 16]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        26\n",
      "          1       0.38      0.73      0.50        22\n",
      "\n",
      "avg / total       0.17      0.33      0.23        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This didn't go anywhere, which doesn't bode well for my capstone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles = df.title.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops = ['data', 'scientist', 'science', 'the', 'a', 'an', 'is', 'senior', 'sr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words=stops, max_features=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "cv.vocabulary_.get(u'security')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
